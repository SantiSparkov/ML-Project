{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import json\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "# Cargar el dataframe\n",
    "data = pd.read_csv('./dataset/train.csv')\n",
    "\n",
    "# 1. Preprocesamiento de texto\n",
    "def convert_to_numeric(value):\n",
    "    if isinstance(value, str):\n",
    "        if 'K' in value:\n",
    "            return float(value.replace('K', '')) * 1_000\n",
    "        elif 'M' in value:\n",
    "            return float(value.replace('M', '')) * 1_000_000\n",
    "    return float(value)\n",
    "\n",
    "data[\"Summary\"] = data[\"Summary\"].fillna(\"\").astype(str)\n",
    "\n",
    "# Crear y ajustar el tokenizer para la columna \"Summary\"\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(data[\"Summary\"])\n",
    "sequences = tokenizer.texts_to_sequences(data[\"Summary\"])\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Guardar el tokenizer como JSON\n",
    "with open(\"tokenizer.json\", \"w\") as f:\n",
    "    json.dump(tokenizer.to_json(), f)\n",
    "\n",
    "# Longitud máxima de secuencia\n",
    "max_length = 50\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Codificar las etiquetas (género)\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Genre\"] = label_encoder.fit_transform(data[\"Genre\"])\n",
    "labels = to_categorical(data[\"Genre\"])\n",
    "\n",
    "# Dividir datos en entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    padded_sequences, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Definir el modelo\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=128, input_length=max_length),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(labels.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# 3. Compilar el modelo\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 4. Entrenar el modelo\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 5. Guardar el modelo con joblib\n",
    "model.save(\"game_genre_model.h5\")  # Guardar el modelo en formato HDF5 para TensorFlow\n",
    "\n",
    "# 6. Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(X_val, y_val, verbose=2)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "# Load the training data again\n",
    "train_data = pd.read_csv('./dataset/train.csv')\n",
    "\n",
    "# Randomly select a subset of rows from the training data for prediction (e.g., 100 samples)\n",
    "random_sample = train_data.sample(n=100, random_state=42)\n",
    "\n",
    "# Preprocess the 'Summary' column in the random sample\n",
    "random_sample[\"Summary\"] = random_sample[\"Summary\"].fillna(\"\").astype(str)\n",
    "\n",
    "# Convert the random sample 'Summary' to sequences and pad them\n",
    "sample_sequences = tokenizer.texts_to_sequences(random_sample[\"Summary\"])\n",
    "sample_padded_sequences = pad_sequences(sample_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(sample_padded_sequences, verbose=1)\n",
    "\n",
    "# Convert predictions to genre labels\n",
    "predicted_genres = label_encoder.inverse_transform(predictions.argmax(axis=1))\n",
    "\n",
    "# Save results to a new CSV file\n",
    "output = pd.DataFrame({\n",
    "    'id': random_sample['id'], \n",
    "    'Genre': predicted_genres\n",
    "})\n",
    "output.to_csv('./dataset/predicted_random_sample_genres.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to './dataset/predicted_random_sample_genres.csv'\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
